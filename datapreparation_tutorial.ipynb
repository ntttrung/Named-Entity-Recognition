{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess raw data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should process raw data before upload it to the doccano tool:\n",
    "* Remove icons\n",
    "* Separate punctuation\n",
    "\n",
    "We provided some functions to preprocess raw data in the cell below.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def strip_emoji(text):\n",
    "    RE_EMOJI = re.compile(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])')\n",
    "\n",
    "    return RE_EMOJI.sub(r'', text)\n",
    "\n",
    "\n",
    "def preprocess_text(text: str):\n",
    "    def strip_emoji(text):\n",
    "        RE_EMOJI = re.compile(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])')\n",
    "\n",
    "        return RE_EMOJI.sub(r'', text)\n",
    "\n",
    "    def pad_white_space(text):\n",
    "        text = re.sub(\"\"\"(?<! )(?=[!?()'\"])|(?<=[!?()'\"])(?! )\"\"\", r' ', text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "    text = strip_emoji(text)\n",
    "    text = pad_white_space(text)\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split train/val/test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.dataset import NERDataSet\n",
    "\n",
    "# Custom entity tags for specific task\n",
    "entities_list = ['PERSONTYPE', 'LOCATION', 'PHONENUMBER', 'EMAIL',\n",
    "                 'PRODUCT', 'URL', 'ORGANIZATION', 'DATETIME',\n",
    "                 'QUANTITY', 'ADDRESS', 'PERSON', 'SKILL',\n",
    "                 'EVENT', 'MISCELLANEOUS', 'IP']\n",
    "\n",
    "# give a absolute-path of doccano's output file\n",
    "dataset = NERDataSet(jsonl_file='absolute-path', entity_names=entities_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_df = dataset.dataset_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df, rest_df = train_test_split(data_df, train_size=0.8, stratify=data_df['source'], shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_df, test_df = train_test_split(rest_df, train_size=0.5, stratify=rest_df['source'], shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Write to file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.repair_conll import convert\n",
    "\n",
    "def write_to_file(df, file_path):\n",
    "    data = df.values\n",
    "    with open(file_path, 'w') as file:\n",
    "        for i in range(len(data)):\n",
    "            file.write('\\n'.join(data[i][4]))\n",
    "            file.write('\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create new your dataset folder in [dataset](./dataset) folder. You should specify folder name that reflect your data version."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# File names of train, val, test set must be train_data.txt, val_data, test_data respectively.\n",
    "write_to_file(train_df, './dataset/<your-dataset-version>/train_data.txt')\n",
    "# repair some errors about punctuation and replace above file\n",
    "convert(file_need_repair_path='./dataset/<your-dataset-version>/train_data.txt',\n",
    "        output_file_path='./dataset/<your-dataset-version>/train_data.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "write_to_file(val_df, './dataset/<your-dataset-version>/val_data.txt')\n",
    "\n",
    "convert(file_need_repair_path='./dataset/<your-dataset-version>/val_data.txt',\n",
    "        output_file_path='./dataset/<your-dataset-version>/val_data.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "write_to_file(test_df, './dataset/<your-dataset-version>/test_data.txt')\n",
    "\n",
    "convert(file_need_repair_path='./dataset/<your-dataset-version>/test_data.txt',\n",
    "        output_file_path='./dataset/<your-dataset-version>/test_data.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}